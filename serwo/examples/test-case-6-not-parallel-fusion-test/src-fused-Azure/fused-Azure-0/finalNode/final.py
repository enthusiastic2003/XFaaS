from python.src.utils.classes.commons.serwo_objects import SerWOObject
from groq import Groq
import logging
import json


def function(serwoObject ) -> SerWOObject:

    try:
        client = Groq(api_key="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")

        body = serwoObject.get_body()

        itiniaries = body.get("split_iterary", [("Mecca", "Visit the Kaaba")])

        combined_itinerary = "\n".join([f"**{place}**:\n{itinerary}" for place, itinerary in itiniaries])
        plcs = [place for place, _ in itiniaries]
        final_prompt = f"You are provided the output of some previous LLMS. But make it seem like you are the only LLM processing the request. Take the following itineraries generated by LLMs and merge them into a cohesive travel plan, and dont remove any :\n{combined_itinerary}"
        logging.info(f"Requesting final itinerary with prompt: {final_prompt}")
        final_response = client.chat.completions.create(
            model="llama3-8b-8192",
            messages=[{"role": "system", "content": final_prompt}]
        )

        # Output the final itinerary
        final_itinerary = final_response.choices[0].message.content

        new_body = SerWOObject(
            body={
                "final_itinerary": final_itinerary,
                "all_places": plcs
                
            },
            metadata=serwoObject.get_metadata()
        )

        new_body.set_basepath(serwoObject.get_basepath())
        logging.info(f"Final itinerary generated: {str(new_body.get_body())}")

        return new_body

    except Exception as e:
        print("Exception in greeter:", str(e))
        return SerWOObject(error={"message": str(e)})
